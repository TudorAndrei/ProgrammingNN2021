{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('pnn': conda)"
  },
  "interpreter": {
   "hash": "083e8d8b437b31bd80b002b4dfb9869f07effbefb6d59f7042b983694f35a0d4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, Activation, Conv2DTranspose, MaxPool2D, Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "from IPython.display import Image, display\n",
    "from skimage.transform import resize\n",
    "from util import color_to_label, label_to_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of samples: 10\n./GW5060/binary/BE_1405_0010.tif | ./GW5060/masks/BE_1405_0010_MASK.png\n./GW5060/binary/BE_1405_0011.tif | ./GW5060/masks/BE_1405_0011_MASK.png\n./GW5060/binary/BE_1405_0012.tif | ./GW5060/masks/BE_1405_0012_MASK.png\n./GW5060/binary/BE_1405_0013.tif | ./GW5060/masks/BE_1405_0013_MASK.png\n./GW5060/binary/BE_1405_0014.tif | ./GW5060/masks/BE_1405_0014_MASK.png\n./GW5060/binary/BE_1405_0015.tif | ./GW5060/masks/BE_1405_0015_MASK.png\n./GW5060/binary/BE_1405_0016.tif | ./GW5060/masks/BE_1405_0016_MASK.png\n./GW5060/binary/BE_1405_0017.tif | ./GW5060/masks/BE_1405_0017_MASK.png\n./GW5060/binary/BE_1405_0018.tif | ./GW5060/masks/BE_1405_0018_MASK.png\n./GW5060/binary/BE_1405_0019.tif | ./GW5060/masks/BE_1405_0019_MASK.png\n"
     ]
    }
   ],
   "source": [
    "# 1903 w\n",
    "# 2981 himport os\n",
    "# IMAGE_SIZE = (1903, 2981)\n",
    "IMAGE_SIZE = (256, 256)\n",
    "\n",
    "input_dir = \"./GW5060/binary\"\n",
    "target_dir = \"./GW5060/masks/\"\n",
    "img_size = (160, 160)\n",
    "num_classes = 3\n",
    "batch_size = 32\n",
    "\n",
    "input_img_paths = sorted(\n",
    "    [\n",
    "        os.path.join(input_dir, fname)\n",
    "        for fname in os.listdir(input_dir)\n",
    "        if fname.endswith(\".tif\")\n",
    "    ]\n",
    ")\n",
    "target_img_paths = sorted(\n",
    "    [\n",
    "        os.path.join(target_dir, fname)\n",
    "        for fname in os.listdir(target_dir)\n",
    "        if fname.endswith(\".png\") and not fname.startswith(\".\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Number of samples:\", len(input_img_paths))\n",
    "\n",
    "for input_path, target_path in zip(input_img_paths[:10], target_img_paths[:10]):\n",
    "    print(input_path, \"|\", target_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image2 = PIL.Image.open(input_img_paths[0])\n",
    "image2_mask = PIL.Image.open(target_img_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(256, 256, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "img_numpy = np.array(image2)\n",
    "img_numpy = resize(img_numpy, IMAGE_SIZE)\n",
    "img_numpy = img_numpy.reshape(IMAGE_SIZE[0], IMAGE_SIZE[1], 1)\n",
    "img_numpy.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(10, 256, 256)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "X_train = np.zeros((len(input_img_paths), IMAGE_SIZE[0], IMAGE_SIZE[1],1))\n",
    "y_train = np.zeros((len(target_img_paths), IMAGE_SIZE[0], IMAGE_SIZE[1]))\n",
    "X_train.shape\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, image in enumerate(input_img_paths):\n",
    "    img = PIL.Image.open(image)\n",
    "    img = np.array(img)\n",
    "    img = resize(img, IMAGE_SIZE)\n",
    "    img = img.reshape(IMAGE_SIZE[0], IMAGE_SIZE[1], 1)\n",
    "    # print(img.shape)\n",
    "    X_train[idx] = img\n",
    "\n",
    "for idx, image in enumerate(target_img_paths):\n",
    "    label_img = PIL.Image.open(image)\n",
    "    label_img = np.array(label_img)\n",
    "    label_img = resize(label_img, IMAGE_SIZE)\n",
    "    # print(label_img.shape)\n",
    "    # label_img = label_img.reshape(IMAGE_SIZE[0], IMAGE_SIZE[1],3)\n",
    "    # print(label_img.shape)\n",
    "    label_img = color_to_label(label_img)\n",
    "    y_train[idx] = label_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = (3,3)\n",
    "model = Sequential([\n",
    "    # Encoder\n",
    "    Input(shape=(256,256,1)),\n",
    "    Conv2D(20, ks, padding='same'),\n",
    "    Activation('relu'),\n",
    "    Conv2D(40, ks, padding='same'),\n",
    "    MaxPool2D(pool_size=(2,2), strides=2),\n",
    "    Conv2D(60, ks, padding='same'),\n",
    "    Activation('relu'),\n",
    "    Conv2D(80, ks, padding='same'),\n",
    "    MaxPool2D(pool_size=(2,2), strides=2),\n",
    "    Conv2D(100, ks, padding='same'),\n",
    "    Activation('relu'),\n",
    "    # Decoder\n",
    "    Conv2DTranspose(80, ks, padding='same'),\n",
    "    Activation('relu'),\n",
    "    Conv2DTranspose(60, ks, strides=(2,2),padding='same'),\n",
    "    Activation('relu'),   \n",
    "    Conv2DTranspose(40, ks, strides=(2,2),padding='same'),\n",
    "    Conv2DTranspose(5, kernel_size=(1,1)),\n",
    "    Activation('softmax'),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 256, 256, 20)      200       \n_________________________________________________________________\nactivation (Activation)      (None, 256, 256, 20)      0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 256, 256, 40)      7240      \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 128, 128, 40)      0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 128, 128, 60)      21660     \n_________________________________________________________________\nactivation_1 (Activation)    (None, 128, 128, 60)      0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 128, 128, 80)      43280     \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 64, 64, 80)        0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 64, 64, 100)       72100     \n_________________________________________________________________\nactivation_2 (Activation)    (None, 64, 64, 100)       0         \n_________________________________________________________________\nconv2d_transpose (Conv2DTran (None, 64, 64, 80)        72080     \n_________________________________________________________________\nactivation_3 (Activation)    (None, 64, 64, 80)        0         \n_________________________________________________________________\nconv2d_transpose_1 (Conv2DTr (None, 128, 128, 60)      43260     \n_________________________________________________________________\nactivation_4 (Activation)    (None, 128, 128, 60)      0         \n_________________________________________________________________\nconv2d_transpose_2 (Conv2DTr (None, 256, 256, 40)      21640     \n_________________________________________________________________\nconv2d_transpose_3 (Conv2DTr (None, 256, 256, 5)       205       \n_________________________________________________________________\nactivation_5 (Activation)    (None, 256, 256, 5)       0         \n=================================================================\nTotal params: 281,665\nTrainable params: 281,665\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'],\n",
    "              optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/2\n",
      "1/1 [==============================] - 11s 11s/step - loss: 1.6049 - accuracy: 0.2463\n",
      "Epoch 2/2\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 1.5515 - accuracy: 0.8733\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb1e94aa050>"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1/1 [==============================] - 0s 251ms/step - loss: 1.3906 - accuracy: 0.9989\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[1.3906495571136475, 0.998919665813446]"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "model.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(10, 256, 256, 5)"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_2 = label_to_colors(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(10, 256, 256, 5, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "y_pred_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-7b30fb2d0346>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg_example\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "img_example = PIL.Image(y_pred_2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}